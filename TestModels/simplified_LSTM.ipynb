{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Baiscs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "import datetime as dt\n",
    "\n",
    "# Stock market \n",
    "import yfinance as yf\n",
    "\n",
    "# ML \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "# Extras\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(units=50, optimizer='adam', batch_size=32, epochs=25):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=units, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=units))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))  # Output layer with 1 unit for predicting 'Close'\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search_and_fit(x_train, y_train, param_grid, n_splits=5):\n",
    "    # Wrap the Keras model so it can be used by scikit-learn GridSearchCV\n",
    "    model = KerasRegressor(model=create_lstm_model, epochs=10, batch_size=32, verbose=1)  # Set verbose to 1 for more output\n",
    "\n",
    "    # Create Time Series Split for cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    # Create Grid Search\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=tscv, verbose=1)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    print(\"Starting grid search...\")\n",
    "    grid_result = grid.fit(x_train, y_train)\n",
    "    print(\"Grid search completed!\")\n",
    "\n",
    "    # Summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "    # Retrieve best hyperparameters\n",
    "    best_batch_size = grid_result.best_params_['batch_size']\n",
    "    best_optimizer = grid_result.best_params_['optimizer']\n",
    "    best_epochs = grid_result.best_params_['epochs']\n",
    "\n",
    "    # Build the final model with the best hyperparameters\n",
    "    print(\"Building final model with best hyperparameters...\")\n",
    "    final_model = create_lstm_model(epochs=best_epochs, optimizer=best_optimizer, batch_size=best_batch_size)\n",
    "    \n",
    "    # Fit the final model\n",
    "    final_model.fit(x_train, y_train)\n",
    "    print(\"Final model training completed!\")\n",
    "\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "ticker_symbol = 'AAPL'\n",
    "start_date = dt.datetime(2010, 1, 1)\n",
    "end_date = dt.datetime(2022, 1, 1)\n",
    "data = yf.download(ticker_symbol, start=start_date, end=end_date)\n",
    "\n",
    "# Prepare Data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data[['Open', 'High', 'Low', 'Volume', 'Close']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_days = 70\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for x in range(prediction_days, len(scaled_data)):\n",
    "    x_train.append(scaled_data[x - prediction_days:x, :])  # Using all four features\n",
    "    y_train.append(scaled_data[x, 4])  # 'Close' is the fourth column (index 3)\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'batch_size': [32],  \n",
    "    'epochs': [25],  \n",
    "    'optimizer': ['adam'], \n",
    "}\n",
    "\n",
    "final_model_1 = perform_grid_search_and_fit(x_train, y_train, param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the end_date to today\n",
    "end_date_today = dt.datetime.now()\n",
    "\n",
    "# Retrieve data from the end_date until today\n",
    "test_data = yf.download(ticker_symbol, start=end_date, end=end_date_today)\n",
    "\n",
    "# Scale the test data using the same scaler\n",
    "scaled_test_data = scaler.transform(test_data[['Open', 'High', 'Low', 'Volume', 'Close']].values)\n",
    "\n",
    "# Create sequences for the test set\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# Use the same prediction_days value as in the training data\n",
    "for x in range(prediction_days, len(scaled_test_data)):\n",
    "    x_test.append(scaled_test_data[x - prediction_days:x, :])\n",
    "    y_test.append(scaled_test_data[x, 4])  # 'Close' is the fifth column (index 4)\n",
    "\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "\n",
    "# Reshape the test set to match the LSTM model's input shape\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "y_pred = final_model.predict(x_test)\n",
    "\n",
    "# Inverse transform the scaled predictions and true values to the original scale\n",
    "y_pred_original = scaler.inverse_transform(np.concatenate((x_test[:, -1, :4], y_pred.reshape(-1, 1)), axis=1))[:, 4]\n",
    "y_test_original = scaler.inverse_transform(np.concatenate((x_test[:, -1, :4], y_test.reshape(-1, 1)), axis=1))[:, 4]\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "r2 = r2_score(y_test_original, y_pred_original)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2) Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual vs predicted closing prices\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_data.index[prediction_days:], y_test_original, label='Actual Close Prices', color='blue')\n",
    "plt.plot(test_data.index[prediction_days:], y_pred_original, label='Predicted Close Prices', color='red', linestyle='--')\n",
    "plt.title('Actual vs Predicted Closing Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
